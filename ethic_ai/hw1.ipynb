{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –±–∏–±–∏–ª–æ—Ç–µ–∫–∏"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–û—Ç–¥–µ–ª–∏–º –∫–æ–ª–æ–Ω–∫–∏ –∏ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞—Ç—å –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ –≤ –±–∏–Ω–∞—Ä–Ω—ã–µ –≤–µ–ª–∏—á–∏–Ω—ã, –≥–¥–µ 1 ‚Äî —Ç–æ–∫—Å–∏—á–Ω—ã–π –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π, –∞ 0 ‚Äî –Ω–µ—Ç–æ–∫—Å–∏—á–Ω—ã–π –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "\n",
    "data = pd.read_csv(\"data/data.csv\")\n",
    "comments = data[\"comment_text\"]\n",
    "target = (data[\"target\"]>0.7).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–í—ã–≤–µ–¥–µ–º –¥–∞–Ω–Ω—ã–µ, —á—Ç–æ–±—ã —É–¥–æ—Å—Ç–æ–≤–µ—Ä–∏—Ç—å—Å—è, —á—Ç–æ –≤—Å–µ —Å–¥–µ–ª–∞–Ω–æ –≤–µ—Ä–Ω–æ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                     haha you guys are a bunch of losers.\n",
       "1        Yet call out all Muslims for the acts of a few...\n",
       "2        This bitch is nuts. Who would read a book by a...\n",
       "3                                         You're an idiot.\n",
       "4        Who cares!? Stark trek and Star Wars fans are ...\n",
       "                               ...                        \n",
       "90897    Methinks Bishop Braxton doth protest too much ...\n",
       "90898    Sounds pretty speculative to me.  But i'm a sp...\n",
       "90899    Seriously!\\nVery proud of our 'domestic progra...\n",
       "90900    Hawaii food is mostly GMO loaded with chemical...\n",
       "90901    Eugenean:  I read hundreds and thousands of ar...\n",
       "Name: comment_text, Length: 90902, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0        1\n",
       "1        1\n",
       "2        1\n",
       "3        1\n",
       "4        1\n",
       "        ..\n",
       "90897    0\n",
       "90898    0\n",
       "90899    0\n",
       "90900    0\n",
       "90901    0\n",
       "Name: target, Length: 90902, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(comments)\n",
    "display(target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–¢–µ–ø–µ—Ä—å —Ä–∞–∑–¥–µ–ª–∏–º –Ω–∞—à–∏ –¥–∞–Ω–Ω—ã–µ –Ω–∞ train –∏ test. –ü—É—Å—Ç—å –≤ —Ç–µ—Å—Ç —É –Ω–∞—Å –ø–æ–π–¥–µ—Ç 30% –¥–∞–Ω–Ω—ã—Ö. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    comments, target, test_size=0.3, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º —Ç–µ–∫—Å—Ç, –∫–æ—Ç–æ—Ä—ã–π –≤—ã –ø–æ–¥–µ–ª–∏–ª–∏ –Ω–∞ train –∏ test, –≤ —á–∏—Å–ª–æ–≤–æ–π —Ñ–æ—Ä–º–∞—Ç —Å –ø–æ–º–æ—â—å—é —Ñ—É–Ω–∫—Ü–∏–∏ CountVectorizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–°–ª–æ–≤–∞—Ä—å: ['00' '000' '0000000000000000000' ... 'ùíïùíâùíÜ' 'ùíïùíê' 'ùìíùì≤ùìøùì≤ùìµ']\n",
      "–§–æ—Ä–º–∞ X_train_norm: (63631, 57878)\n",
      "–§–æ—Ä–º–∞ X_test_norm : (27271, 57878)\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "X_train_norm = vectorizer.fit_transform(X_train)\n",
    "X_test_norm = vectorizer.transform(X_test)\n",
    "print(\"–°–ª–æ–≤–∞—Ä—å:\", vectorizer.get_feature_names_out())\n",
    "print(\"–§–æ—Ä–º–∞ X_train_norm:\", X_train_norm.shape)\n",
    "print(\"–§–æ—Ä–º–∞ X_test_norm :\", X_test_norm.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–≤ –∫–∞—á–µ—Å—Ç–≤–µ –º–æ–¥–µ–ª–∏, –∫–æ—Ç–æ—Ä–∞—è –±—É–¥–µ—Ç –∫–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞—Ç—å –Ω–∞–º –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏ –Ω–∞ —Ç–æ–∫—Å–∏—á–Ω—ã–µ –∏ –Ω–µ—Ç–æ–∫—Å–∏—á–Ω—ã–µ, –≤–æ–∑—å–º–µ–º –ª–æ–≥–∏—Å—Ç–∏—á–µ—Å–∫—É—é —Ä–µ–≥—Ä–µ—Å—Å–∏—é —Å –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–º max_iter=2000. –î–ª—è –æ—Ü–µ–Ω–∫–∏ –º–æ–¥–µ–ª–∏ –≤–æ–∑—å–º–µ–º –º–µ—Ç—Ä–∏–∫—É accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9279454365443145\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(max_iter=2000)\n",
    "model.fit(X_train_norm, y_train)\n",
    "\n",
    "# –¥–µ–ª–∞–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –Ω–∞ —Ç–µ—Å—Ç–µ\n",
    "y_pred = model.predict(X_test_norm)\n",
    "\n",
    "# —Å—á–∏—Ç–∞–µ–º accuracy\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ü—Ä–æ–ø–∏—à–µ–º –Ω–∏–∂–µ —Ñ—É–Ω–∫—Ü–∏—é, –¥–ª—è –∫–æ—Ç–æ—Ä–æ–π –Ω–∞ –≤—Ö–æ–¥ –º—ã –±—ã –ø–æ–¥–∞–≤–∞–ª–∏ –Ω–∞—à –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π, –∞ –Ω–∞ –≤—ã—Ö–æ–¥ –ø–æ–ª—É—á–∞–ª–∏ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ, –Ω–∞—Å–∫–æ–ª—å–∫–æ –æ—Ç 0 –¥–æ 1 –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π —è–≤–ª—è–µ—Ç—Å—è —Ç–æ–∫—Å–∏—á–Ω—ã–º."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å —Ç–æ–∫—Å–∏—á–Ω–æ—Å—Ç–∏: 0.120\n"
     ]
    }
   ],
   "source": [
    "def predict_toxicity(comment: str) -> float:\n",
    "    X_new = vectorizer.transform([comment])\n",
    "    proba = model.predict_proba(X_new)[0][1]\n",
    "    return proba\n",
    "\n",
    "example = \"Test comment\"\n",
    "score = predict_toxicity(example)\n",
    "print(f\"–í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å —Ç–æ–∫—Å–∏—á–Ω–æ—Å—Ç–∏: {score:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ü–æ–ø—Ä–æ–±—É–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞—Ç—å, —Ç–æ–∫—Å–∏—á–µ–Ω –ª–∏ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π ¬´Apples are stupid¬ª. –ü–æ—Ç–æ–º –ø—Ä–µ–¥—Å–∫–∞–∂–µ–º, —Ç–æ–∫—Å–∏—á–µ–Ω –ª–∏ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π ¬´I love apples¬ª."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å —Ç–æ–∫—Å–∏—á–Ω–æ—Å—Ç–∏ —Ç–æ–∫—Å–∏—á–Ω–æ–≥–æ –∫–æ–º–º–µ–Ω—Ç—Ä–∏—è: 0.999\n",
      "–í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å —Ç–æ–∫—Å–∏—á–Ω–æ—Å—Ç–∏ –Ω–µ—Ç–æ–∫—Å–∏—á–Ω–æ–≥–æ –∫–æ–º–º–µ–Ω—Ç—Ä–∏—è: 0.058\n"
     ]
    }
   ],
   "source": [
    "toxic_comment = 'Apples are stupid'\n",
    "non_toxic_comment = 'I love apples'\n",
    "\n",
    "score_toxic = predict_toxicity(toxic_comment)\n",
    "score_non_toxic = predict_toxicity(non_toxic_comment)\n",
    "\n",
    "print(f\"–í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å —Ç–æ–∫—Å–∏—á–Ω–æ—Å—Ç–∏ —Ç–æ–∫—Å–∏—á–Ω–æ–≥–æ –∫–æ–º–º–µ–Ω—Ç—Ä–∏—è: {score_toxic:.3f}\")\n",
    "print(f\"–í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å —Ç–æ–∫—Å–∏—á–Ω–æ—Å—Ç–∏ –Ω–µ—Ç–æ–∫—Å–∏—á–Ω–æ–≥–æ –∫–æ–º–º–µ–Ω—Ç—Ä–∏—è: {score_non_toxic:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–í—ã–≤–µ–¥–µ–º –¥–µ—Å—è—Ç—å —Å–ª–æ–≤, –∫–æ—Ç–æ—Ä—ã–µ —Å—á–∏—Ç–∞—é—Ç—Å—è –Ω–∞–∏–±–æ–ª–µ–µ —Ç–æ–∫—Å–∏—á–Ω—ã–º–∏, –∞ —Ç–∞–∫–∂–µ –∏—Ö –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç—ã.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stupid: 9.1988\n",
      "idiot: 8.7349\n",
      "idiots: 8.4570\n",
      "stupidity: 7.5453\n",
      "idiotic: 6.8279\n",
      "crap: 6.5746\n",
      "dumb: 6.4499\n",
      "pathetic: 6.4234\n",
      "hypocrite: 6.3885\n",
      "moron: 6.3644\n"
     ]
    }
   ],
   "source": [
    "vocab = vectorizer.vocabulary_\n",
    "coefs = model.coef_[0]\n",
    "\n",
    "word_weights = [\n",
    "    (word, coefs[vocab[word]])\n",
    "    for word in vocab.keys()\n",
    "]\n",
    "\n",
    "top10 = sorted(word_weights, key=lambda x: x[1], reverse=True)[:10]\n",
    "for word, weight in top10:\n",
    "    print(f\"{word}: {weight:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–í–∑–≥–ª—è–Ω–∏—Ç–µ –Ω–∞ —Å–∞–º—ã–µ —Ç–æ–∫—Å–∏—á–Ω—ã–µ —Å–ª–æ–≤–∞ –∏–∑ –∑–∞–¥–∞–Ω–∏—è 6. –í—ã–∑—ã–≤–∞—é—Ç –ª–∏ —É –≤–∞—Å —É–¥–∏–≤–ª–µ–Ω–∏–µ –∫–∞–∫–∏–µ-–Ω–∏–±—É–¥—å –∏–∑ –Ω–∏—Ö? –ï—Å—Ç—å –ª–∏ —Å–ª–æ–≤–∞, –∫–æ—Ç–æ—Ä—ã—Ö, –∫–∞–∂–µ—Ç—Å—è, –Ω–µ –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å –≤ —Å–ø–∏—Å–∫–µ?\n",
    "\n",
    "–û—Ç–≤–µ—Ç:\n",
    "\n",
    "–ù–∞ –ø–µ—Ä–≤—ã–π –≤–∑–≥–ª—è–¥, –ª–∏—à–Ω–∏—Ö —Å–ª–æ–≤ –Ω–µ—Ç. –í–æ–∑–º–æ–∂–Ω–æ —Å—Ç–æ–∏—Ç –æ–±—Ä–∞—Ç–∏—Ç—å –≤–Ω–∏–º–∞–Ω–∏–µ –Ω–∞ —Å–ª–æ–≤–æ \"stupidity\", –∏–∞–∫ –∫–∞–∫ —Å–ª–æ–≤–æ \"–≥–ª—É–ø–æ—Å—Ç—å\" —Å–∞–º–æ –ø–æ —Å–µ–±–µ –Ω–µ —è–≤–ª—è–µ—Ç—Å—è —Ç–æ–∫—Å–∏—á–Ω—ã–º –∏ –º–æ–∂–µ—Ç –±—ã—Ç—å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–æ –≤ –Ω–µ —Ç–æ–∫—Å–∏—á–Ω–æ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ—é"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–î–∞–≤–∞–π—Ç–µ –ø–æ—Å–º–æ—Ç—Ä–∏–º, –∫–∞–∫ –≤–∞—à –∞–ª–≥–æ—Ä–∏—Ç–º –∫–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä—É–µ—Ç —Å–ª–µ–¥—É—é—â–∏–µ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏:\n",
    "\n",
    "\"I have a christian friend\"\n",
    "\"I have a muslim friend\"\n",
    "\"I have a white friend\"\n",
    "\"I have a black friend\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–§—Ä–∞–∑–∞ \"I have a christian friend\" —è–≤–ª—è–µ—Ç—Å—è —Ç–æ–∫—Å–∏—á–Ω–æ–π —Å –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å—é 0.18648912185234992\n",
      "–§—Ä–∞–∑–∞ \"I have a muslim friend\" —è–≤–ª—è–µ—Ç—Å—è —Ç–æ–∫—Å–∏—á–Ω–æ–π —Å –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å—é 0.512137300359607\n",
      "–§—Ä–∞–∑–∞ \"I have a white friend\" —è–≤–ª—è–µ—Ç—Å—è —Ç–æ–∫—Å–∏—á–Ω–æ–π —Å –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å—é 0.4045665156940112\n",
      "–§—Ä–∞–∑–∞ \"I have a black friend\" —è–≤–ª—è–µ—Ç—Å—è —Ç–æ–∫—Å–∏—á–Ω–æ–π —Å –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å—é 0.5882626923835796\n"
     ]
    }
   ],
   "source": [
    "test_phrases = [\"I have a christian friend\",\n",
    "\"I have a muslim friend\",\n",
    "\"I have a white friend\",\n",
    "\"I have a black friend\"]\n",
    "\n",
    "for phrase in test_phrases:\n",
    "    score = predict_toxicity(phrase)\n",
    "    print(f'–§—Ä–∞–∑–∞ \"{phrase}\" —è–≤–ª—è–µ—Ç—Å—è —Ç–æ–∫—Å–∏—á–Ω–æ–π —Å –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å—é {score}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ß—Ç–æ –¥—É–º–∞–µ—Ç–µ –æ –ø–æ–ª—É—á–∏–≤—à–∏—Ö—Å—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞—Ö? –ï—Å—Ç—å –ª–∏ —É –º–æ–¥–µ–ª–∏ bias? –≠—Ç–∏—á–µ–Ω –ª–∏ –æ–Ω?\n",
    "\n",
    "\n",
    "–û—Ç–≤–µ—Ç:\n",
    "–£ –º–æ–¥–µ–ª–∏ –¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ –µ—Å—Ç—å –ø—Ä–µ–¥–≤–∑—è—Ç–æ—Å—Ç—å –ø–æ —Ä–∞—Å—Å–æ–≤–æ–º—É –∏ —Ä–µ–ª–∏–≥–∏–æ–∑–Ω–æ–º—É –ø—Ä–∏–∑–Ω–∞–∫—É."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–í—ã –∑–∞–º–µ—Ç–∏–ª–∏, —á—Ç–æ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏, –æ—Ç–Ω–æ—Å—è—â–∏–µ—Å—è –∫ –∏—Å–ª–∞–º—É, —Å –±–æ–ª—å—à–µ–π –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å—é –±—É–¥—É—Ç —Ç–æ–∫—Å–∏—á–Ω—ã–º–∏, —á–µ–º –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏, –æ—Ç–Ω–æ—Å—è—â–∏–µ—Å—è –∫ –¥—Ä—É–≥–∏–º —Ä–µ–ª–∏–≥–∏—è–º, –ø–æ—Å–∫–æ–ª—å–∫—É –æ–Ω–ª–∞–π–Ω-—Å–æ–æ–±—â–µ—Å—Ç–≤–æ –∏—Å–ª–∞–º–æ—Ñ–æ–±–Ω–æ. –ö–∞–∫–æ–π —Ç–∏–ø –ø—Ä–µ–¥–≤–∑—è—Ç–æ—Å—Ç–∏ —ç—Ç–æ –º–æ–∂–µ—Ç –≤–Ω–µ—Å—Ç–∏ –≤ –≤–∞—à—É –º–æ–¥–µ–ª—å?\n",
    "\n",
    "–û—Ç–≤–µ—Ç:\n",
    " \n",
    "–û–±—ã—á–Ω–æ —Ç–∞–∫–æ–π —Ç–∏–ø –ø—Ä–µ–¥–≤–∑—è—Ç–æ—Å—Ç–∏ –Ω–∞–∑—ã–≤–∞—é—Ç –ø—Ä–µ–¥–≤–∑—è—Ç–æ—á—Ç—å—é –≤—ã–±–æ—Ä–∫–∏, —Ç–∞–∫ –∫–∞–∫ –≤ –≤—ã–±–æ—Ä–∫–µ –±—ã–ª–æ –±–æ–ª—å—à–µ —Ç–æ–∫—Å–∏—á–Ω—ã—Ö –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã—Ö —Ä–∞—Å—Å –∏ —Ä–µ–ª–∏–≥–∏–π."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ü–æ–¥—É–º–∞–π—Ç–µ –æ —Ç–æ–º, –∫–∞–∫ –º–æ–∂–Ω–æ —É–ª—É—á—à–∏—Ç—å –∞–ª–≥–æ—Ä–∏—Ç–º, —á—Ç–æ–±—ã —Å–¥–µ–ª–∞—Ç—å –µ–≥–æ –±–æ–ª–µ–µ —ç—Ç–∏—á–Ω—ã–º. –ù–∞–ø–∏—à–∏—Ç–µ 1‚Äì2 –∏–¥–µ–∏.\n",
    "\n",
    "–û—Ç–≤–µ—Ç:\n",
    "\n",
    "–í–æ-–ø–µ—Ä–≤—ã—Ö, –º–æ–∂–Ω–æ –±—ã–ª–æ –±—ã —É—Ä–æ–≤–Ω–æ–≤–µ—Å–∏—Ç—å —É–ø–æ–º–∏–Ω–∞–Ω–∏–µ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö —Ä–∞—Å—Å –∏ —Ä–µ–ª–∏–≥–∏–π –∫–∞–∫ –≤ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏—è—Ö, –∫–æ—Ç–æ—Ä—ã–µ —Å—á–∏—Ç–∞—é—Ç—Å—è —Ç–æ–∫—Å–∏—á–Ω—ã–º–∏, —Ç–∞–∫ –∏ –≤ –∫–æ–º–º–µ–Ω—Ç—Ä–∏—è—Ö, –∫–æ—Ç–æ—Ä—ã–µ —è–≤–ª—è—é—Ç—Å—è –Ω–µ—Ç–æ–∫—Å–∏—á–Ω—ã–º–∏. \n",
    "\n",
    "–í–æ-–≤—Ç–æ—Ä—ã—Ö, –º–æ–∂–Ω–æ –±—ã–ª–æ –±—ã –≤ —Ü–µ–ª–æ–º —É–±—Ä–∞—Ç—å –ø—Ä–∏–º–µ—Ä—ã, –∫–æ—Ç–æ—Ä—ã–µ –∑–∞—Ç—Ä–∞–≥–∏–≤–∞—é—Ç –∫–∞–∫–∏–µ-—Ç–æ –∞—Å–ø–µ–∫—Ç—ã —á—É–≤—Å—Ç–≤–∏—Ç–µ–ª—å–Ω—ã—Ö —Ç–µ–º, –Ω–æ —Ç–æ–≥–¥–∞ –º–æ–¥–µ–ª—å –º–æ–≥–ª–∞ –±—ã –Ω–µ —É—á–∏—Ç—ã–≤–∞—Ç—å –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç, —Ç–∞–∫ –∫–∞–∫ –≤ –≤—ã–±–æ—Ä–∫–µ –±—ã –æ—Ç—Å—É—Ç—Å—Ç–≤–æ–≤–∞–ª–∏ –ø—Ä–∏–º–µ—Ä—ã —Å —Ç–∞–∫–∏–º —Å–æ–¥–µ—Ä–∂–∞–Ω–∏–µ–º "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
